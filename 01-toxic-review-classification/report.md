# Практическое задание 1
Есаян Марк Леванович, msp241

## Решение
Выполнено в виде 2х ipynb файлов DataProcess.ipynb && Model.ipynb

## Проблемы
Во время работы возникали вопросы что и как делать, однако интернет полон примеров того,
как вообще используются модели (классические и трансформеры)

Изучение обширных примеров и тех доков на эту тему позволили решить все вопросы связанные с этой работой
## Анализ матрицы несоответсвий
Для построенной модели LogReg была высчитана матрциа несоответсвия:

|   | negative | positive|
|---|---|---|
| false |997|13|
| true |108|134|


Исходя из матрицы несоответсвий видим, что модель хорошо угадывает true negative случаи
а true postive наоборот - неохотно

Это вызвано тем, что в датасете много нетоксичных примеров из-за чего модель
начала чаще стараться сказать что текст нетоксичный. Это делает модель специфичной

Из этого можно сказать, что взяв датасет с большим количеством токсичного текста - модель скорее всего провалится

## Сравнение моделей
В результате валидации всех моделей на одном отложеном eval наборе данных были получены результаты работы всех реализованных моделей

|Model  |  Accuracy |  Precision |  Recall |  F1 Score |
|---|---|---|---|---|
|   LogReg| 0.901  | 0.939  |   0.872  | **0.680**
|   RanFor|  0.969 |  0.966 | 0.872  |   **0.917** |
|   RoBERTa| 0.923 |   0.921 |   0.923 |  **0.922** |
|  CodeBERT|   0.919 |   0.919 | 0.919 | **0.919** |


Из представленных результатов можно сделать вывод что, 
очевидно, тяжелые претрейнед трансформеры справились со своей задачей лучше чем классические модели. 
Однако Random Forest близок к результатам этих моделей по F1Score и даже превосходит трансформеры по accuracy. 
Этому может быть причиной плохое распределение выборки в датасете, что делает модель специфической. 
Поэтому BERT модели выглядят более привлекательными для использования в классификациионной проблеме этой работы.