{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf96378b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: contractions in /home/mark/.local/lib/python3.10/site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /home/mark/.local/lib/python3.10/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: pyahocorasick in /home/mark/.local/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n",
      "Requirement already satisfied: anyascii in /home/mark/.local/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mark/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/mark/.local/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.3.23)\n",
      "Requirement already satisfied: tqdm in /home/mark/.local/lib/python3.10/site-packages (from nltk) (4.66.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/mark/.local/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/mark/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: evaluate in /home/mark/.local/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: multiprocess in /home/mark/.local/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/mark/.local/lib/python3.10/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /home/mark/.local/lib/python3.10/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.0)\n",
      "Requirement already satisfied: dill in /home/mark/.local/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/mark/.local/lib/python3.10/site-packages (from evaluate) (3.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/mark/.local/lib/python3.10/site-packages (from evaluate) (0.26.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/mark/.local/lib/python3.10/site-packages (from evaluate) (4.66.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/mark/.local/lib/python3.10/site-packages (from evaluate) (2024.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/mark/.local/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from datasets>=2.0.0->evaluate) (3.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/lib/python3/dist-packages (from datasets>=2.0.0->evaluate) (3.8.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mark/.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/mark/.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mark/.local/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mark/.local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mark/.local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->evaluate) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mark/.local/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install nltk\n",
    "!pip install contractions\n",
    "!pip install pandas\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "105e121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_PATTERNS = {\n",
    "\n",
    "    ' fuck ':\n",
    "        [\n",
    "            '(f)(u|[^a-z0-9 ])(c|[^a-z0-9 ])(k|[^a-z0-9 ])([^ ])*',\n",
    "            '(f)([^a-z]*)(u)([^a-z]*)(c)([^a-z]*)(k)',\n",
    "            ' f[!@#\\$%\\^\\&\\*]*u[!@#\\$%\\^&\\*]*k', 'f u u c',\n",
    "            '(f)(c|[^a-z ])(u|[^a-z ])(k)', r'f\\*',\n",
    "            'feck ', ' fux ', 'f\\*\\*',\n",
    "            'f\\-ing', 'f\\.u\\.', 'f###', ' fu ', 'f@ck', 'f u c k', 'f uck', 'f ck'\n",
    "\n",
    "        ],\n",
    "\n",
    "    ' crap ':\n",
    "        [\n",
    "            ' (c)(r|[^a-z0-9 ])(a|[^a-z0-9 ])(p|[^a-z0-9 ])([^ ])*',\n",
    "            ' (c)([^a-z]*)(r)([^a-z]*)(a)([^a-z]*)(p)',\n",
    "            ' c[!@#\\$%\\^\\&\\*]*r[!@#\\$%\\^&\\*]*p', 'cr@p', ' c r a p',\n",
    "\n",
    "        ],\n",
    "\n",
    "    ' ass ':\n",
    "        [\n",
    "            '[^a-z]ass ', '[^a-z]azz ', 'arrse', ' arse ', '@\\$\\$'\n",
    "                                                           '[^a-z]anus', ' a\\*s\\*s', '[^a-z]ass[^a-z ]',\n",
    "            'a[@#\\$%\\^&\\*][@#\\$%\\^&\\*]', '[^a-z]anal ', 'a s s'\n",
    "        ],\n",
    "\n",
    "    ' ass hole ':\n",
    "        [\n",
    "            ' a[s|z]*wipe', 'a[s|z]*[w]*h[o|0]+[l]*e', '@\\$\\$hole'\n",
    "        ],\n",
    "\n",
    "    ' bitch ':\n",
    "        [\n",
    "            'bitches', ' b[w]*i[t]*ch', ' b!tch',\n",
    "            ' bi\\+ch', ' b!\\+ch', ' (b)([^a-z]*)(i)([^a-z]*)(t)([^a-z]*)(c)([^a-z]*)(h)',\n",
    "            ' biatch', ' bi\\*\\*h', ' bytch', 'b i t c h'\n",
    "        ],\n",
    "\n",
    "    ' bastard ':\n",
    "        [\n",
    "            'ba[s|z]+t[e|a]+rd'\n",
    "        ],\n",
    "\n",
    "    ' transgender':\n",
    "        [\n",
    "            'transgender'\n",
    "        ],\n",
    "\n",
    "    ' gay ':\n",
    "        [\n",
    "            'gay', 'homo'\n",
    "        ],\n",
    "\n",
    "    ' cock ':\n",
    "        [\n",
    "            '[^a-z]cock', 'c0ck', '[^a-z]cok ', 'c0k', '[^a-z]cok[^aeiou]', ' cawk',\n",
    "            '(c)([^a-z ])(o)([^a-z ]*)(c)([^a-z ]*)(k)', 'c o c k'\n",
    "        ],\n",
    "\n",
    "    ' dick ':\n",
    "        [\n",
    "            ' dick[^aeiou]', 'd i c k'\n",
    "        ],\n",
    "\n",
    "    ' suck ':\n",
    "        [\n",
    "            'sucker', '(s)([^a-z ]*)(u)([^a-z ]*)(c)([^a-z ]*)(k)', 'sucks', '5uck', 's u c k'\n",
    "        ],\n",
    "\n",
    "    ' cunt ':\n",
    "        [\n",
    "            'cunt', 'c u n t'\n",
    "        ],\n",
    "\n",
    "    ' bull shit ':\n",
    "        [\n",
    "            'bullsh\\*t', 'bull\\$hit', 'bull sh.t'\n",
    "        ],\n",
    "\n",
    "    ' jerk ':\n",
    "        [\n",
    "            'jerk'\n",
    "        ],\n",
    "\n",
    "    ' idiot ':\n",
    "        [\n",
    "            'i[d]+io[t]+', '(i)([^a-z ]*)(d)([^a-z ]*)(i)([^a-z ]*)(o)([^a-z ]*)(t)', 'idiots' 'i d i o t'\n",
    "        ],\n",
    "\n",
    "    ' dumb ':\n",
    "        [\n",
    "            '(d)([^a-z ]*)(u)([^a-z ]*)(m)([^a-z ]*)(b)'\n",
    "        ],\n",
    "\n",
    "    ' shit ':\n",
    "        [\n",
    "            'shitty', '(s)([^a-z ]*)(h)([^a-z ]*)(i)([^a-z ]*)(t)', 'shite', '\\$hit', 's h i t', 'sh\\*tty',\n",
    "            'sh\\*ty', 'sh\\*t'\n",
    "        ],\n",
    "\n",
    "    ' shit hole ':\n",
    "        [\n",
    "            'shythole', 'sh.thole'\n",
    "        ],\n",
    "\n",
    "    ' retard ':\n",
    "        [\n",
    "            'returd', 'retad', 'retard', 'wiktard', 'wikitud'\n",
    "        ],\n",
    "\n",
    "    ' rape ':\n",
    "        [\n",
    "            'raped'\n",
    "        ],\n",
    "\n",
    "    ' dumb ass':\n",
    "        [\n",
    "            'dumbass', 'dubass'\n",
    "        ],\n",
    "\n",
    "    ' ass head':\n",
    "        [\n",
    "            'butthead'\n",
    "        ],\n",
    "\n",
    "    ' sex ':\n",
    "        [\n",
    "            'sexy', 's3x', 'sexuality'\n",
    "        ],\n",
    "\n",
    "    ' nigger ':\n",
    "        [\n",
    "            'nigger', 'ni[g]+a', ' nigr ', 'negrito', 'niguh', 'n3gr', 'n i g g e r'\n",
    "        ],\n",
    "\n",
    "    ' shut the fuck up':\n",
    "        [\n",
    "            ' stfu' '^stfu'\n",
    "        ],\n",
    "\n",
    "    ' for your fucking information':\n",
    "        [\n",
    "            ' fyfi', '^fyfi'\n",
    "        ],\n",
    "    ' get the fuck off':\n",
    "        [\n",
    "            'gtfo', '^gtfo'\n",
    "        ],\n",
    "\n",
    "    ' oh my fucking god ':\n",
    "        [\n",
    "            ' omfg', '^omfg'\n",
    "        ],\n",
    "\n",
    "    ' what the hell ':\n",
    "        [\n",
    "            ' wth', '^wth'\n",
    "        ],\n",
    "\n",
    "    ' what the fuck ':\n",
    "        [\n",
    "            ' wtf', '^wtf'\n",
    "        ],\n",
    "    ' son of bitch ':\n",
    "        [\n",
    "            ' sob ', '^sob '\n",
    "        ],\n",
    "\n",
    "    ' pussy ':\n",
    "        [\n",
    "            'pussy[^c]', 'pusy', 'pussi[^l]', 'pusses', '(p)(u|[^a-z0-9 ])(s|[^a-z0-9 ])(s|[^a-z0-9 ])(y)',\n",
    "        ],\n",
    "\n",
    "    ' faggot ':\n",
    "        [\n",
    "            'faggot', ' fa[g]+[s]*[^a-z ]', 'fagot', 'f a g g o t', 'faggit',\n",
    "            '(f)([^a-z ]*)(a)([^a-z ]*)([g]+)([^a-z ]*)(o)([^a-z ]*)(t)', 'fau[g]+ot', 'fae[g]+ot',\n",
    "        ],\n",
    "\n",
    "    ' mother fucker':\n",
    "        [\n",
    "            ' motha f', ' mother f', 'motherucker', ' mofo', ' mf ',\n",
    "        ],\n",
    "\n",
    "    ' whore ':\n",
    "        [\n",
    "            'wh\\*\\*\\*', 'w h o r e'\n",
    "        ],\n",
    "\n",
    "    ' haha ':\n",
    "        [\n",
    "            'ha\\*\\*\\*ha',\n",
    "        ],\n",
    "    # ' what the fuck ':\n",
    "    # [\n",
    "    #     ' wtf',\n",
    "    # ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5bffe93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mark/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mark/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/mark/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import contractions\n",
    "import re, string\n",
    "from nltk import word_tokenize, sent_tokenize, download\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "download('stopwords')\n",
    "download('punkt')\n",
    "download('punkt_tab')\n",
    "\n",
    "\n",
    "def prepare(raw_data: Path) -> datasets.Dataset:\n",
    "    dataset = pd.read_excel(raw_data)\n",
    "    dataset = dataset.dropna()\n",
    "    \n",
    "    dataset[\"message\"] = dataset[\"message\"].apply(lambda sample: process(sample))\n",
    "    dataset[\"message\"] = dataset[\"message\"].apply(lambda x: ' '.join(x))\n",
    "    dataset[\"message\"] = dataset[\"message\"][dataset[\"message\"].apply(len) > 0]\n",
    "    dataset = dataset.drop_duplicates(subset=[\"message\"])\n",
    "    dataset = dataset.dropna()\n",
    "    print(dataset)\n",
    "    return datasets.Dataset.from_pandas(dataset)\n",
    "\n",
    "\n",
    "def load_dataset(path: Path) -> datasets.Dataset:\n",
    "    return datasets.load_from_disk(str(path))\n",
    "\n",
    "\n",
    "def save_dataset(dataset: datasets.Dataset, path: Path) -> None:\n",
    "    dataset.save_to_disk(str(path))\n",
    "    \n",
    "\n",
    "url_regex = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "def process(data):\n",
    "    data = url_regex.sub(\" \", data) # urls    \n",
    "    data = data.lower()\n",
    "\n",
    "    \n",
    "    data = re.compile(r\"(.)\\1{2,}\", re.DOTALL).sub(r\"\\1\", data) # remove repeated\n",
    "    \n",
    "    for target, patterns in RE_PATTERNS.items():\n",
    "        for pat in patterns:\n",
    "            data = re.sub(pat, target, data)\n",
    "            \n",
    "    data = re.sub(r\"[^a-z' ]\", ' ', data)\n",
    "    \n",
    "    data = contractions.fix(data)\n",
    "    data = re.compile('([^\\s\\w]|_)+').sub(' ', data)\n",
    "\n",
    "    \n",
    "    data = word_tokenize(data)\n",
    "    return [word for word in data if word not in stopwords.words('english')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f95168b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 message  is_toxic\n",
      "0                               assignments also removed         0\n",
      "1                               flavor id self flavor id         0\n",
      "2                             bool session adopted false         0\n",
      "3      nit starting c could done directly declaration...         0\n",
      "4      confused tar process checking exited need kill...         0\n",
      "...                                                  ...       ...\n",
      "19643                             love great fix factory         0\n",
      "19644                                     page fantastic         0\n",
      "19646   amazing bet contributed lot slowdown nice rhymes         0\n",
      "19647                                        great catch         0\n",
      "19650  wait seeing nuances affect numbers cock pit go...         0\n",
      "\n",
      "[12517 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e795ec5a278466fa7d36a39cb9e4b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/12517 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "dataset = prepare(\"./code-review-dataset-full.xlsx\")\n",
    "save_dataset(dataset, \"./prepared-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f076999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
